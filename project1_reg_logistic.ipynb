{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from data_analysis_logistic import *\n",
    "from implementation import *\n",
    "from cross_validation_reg_logistic import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"data/train.csv\" # download train data and supply path\n",
    "y_tr, tX_tr, ids_tr = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = \"data/test.csv\" #download train data and supply path\n",
    "y_fin, tX_fin, ids_fin = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_num = 0\n",
    "y0_tr, tX0_tr,y0_tr_new, tX0_tr_new, ids0_tr, y0_te, tX0_te, ids0_te, y0_fin, tX0_fin, ids0_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 1\n",
    "y1_tr, tX1_tr,y1_tr_new, tX1_tr_new, ids1_tr,y1_te, tX1_te, ids1_te, y1_fin, tX1_fin, ids1_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 2\n",
    "y2_tr, tX2_tr,y2_tr_new, tX2_tr_new, ids2_tr,y2_te, tX2_te, ids2_te, y2_fin, tX2_fin, ids2_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 3\n",
    "y3_tr, tX3_tr,y3_tr_new, tX3_tr_new, ids3_tr,y3_te, tX3_te, ids3_te, y3_fin, tX3_fin, ids3_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92898,)\n",
      "(71338,)\n",
      "(43964,)\n",
      "(19115,)\n"
     ]
    }
   ],
   "source": [
    "print(y0_tr.shape)\n",
    "print(y1_tr.shape)\n",
    "print(y2_tr.shape)\n",
    "print(y3_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w0=np.zeros(tX0_tr.shape[1])\n",
    "init_w1=np.zeros(tX1_tr.shape[1])\n",
    "init_w2=np.zeros(tX2_tr.shape[1])\n",
    "init_w3=np.zeros(tX3_tr.shape[1])\n",
    "\n",
    "init_w0_new=np.zeros(tX0_tr_new.shape[1])\n",
    "init_w1_new=np.zeros(tX1_tr_new.shape[1])\n",
    "init_w2_new=np.zeros(tX2_tr_new.shape[1])\n",
    "init_w3_new=np.zeros(tX3_tr_new.shape[1])\n",
    "\n",
    "best_lambdas = [0., 0., 0., 0.,]\n",
    "\n",
    "max_iters=40\n",
    "gamma=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No cross validation - no extended feature - no separation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats:\n",
    "- Categorical accuracy: 0.663\n",
    "- F1-Score: 0.362\n",
    "- Our grade: 0.642 - 0.657*\n",
    "\n",
    "*Non testé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.723357536499335\n"
     ]
    }
   ],
   "source": [
    "ratio=0.8\n",
    "X_tr, X_te, Y_tr, Y_te, IDS_tr, IDS_te=split_data(tX_tr, y_tr, ids_tr, ratio, seed=1)\n",
    "X_tr, m, std = standardize(X_tr)\n",
    "X_te = standardize_te(X_te, m, std)\n",
    "X_tr,IDS_tr,Y_tr=extract_outliers(X_tr,IDS_tr,Y_tr)\n",
    "X_te,IDS_te,Y_te=extract_outliers(X_te,IDS_te,Y_te)\n",
    "\n",
    "init_w=np.zeros(X_tr.shape[1])\n",
    "best_lambda=test_lambda_cst(Y_tr,X_tr,Y_te,X_te,init_w, max_iters, gamma)\n",
    "\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6566727928965258\n"
     ]
    }
   ],
   "source": [
    "w, loss = reg_logistic_regression(Y_tr, X_tr,init_w, best_lambda, max_iters, gamma)\n",
    "\n",
    "y_pred = predict_labels(w, X_te)\n",
    "\n",
    "res = np.where(Y_te[:,] == y_pred[:,], 1, 0)\n",
    "grade = np.mean(res)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w=np.zeros(tX_tr.shape[1])\n",
    "w, loss = reg_logistic_regression(y_tr, tX_tr,init_w, best_lambda, max_iters, gamma)\n",
    "\n",
    "y_pred = predict_labels(w, tX_fin)\n",
    "y_pred=rescale_y(y_pred, ids_fin, 0,-1)\n",
    "ids_pred = ids_fin\n",
    "OUTPUT_PATH = 'results_reg_logistic_nocross_noext_nosep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation of lambda - No extended feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats:\n",
    "- Categorical accuracy: 0.687\n",
    "- F1-Score: 0.591\n",
    "- Our grade: 0.695 - 0.710*\n",
    "\n",
    "\n",
    "A revoir: Les lambdas sont ils bien definies? Notamment pour lambda 0.\n",
    "\n",
    "*pas encore soumis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00379269019073225, 1e-05, 0.11288378916846883, 0.00379269019073225]\n"
     ]
    }
   ],
   "source": [
    "best_lambdas[0]= cross_validation_lambda_reg_logistic(y0_tr, tX0_tr, max_iters, gamma)\n",
    "best_lambdas[1]= cross_validation_lambda_reg_logistic(y1_tr, tX1_tr, max_iters, gamma)\n",
    "best_lambdas[2]= cross_validation_lambda_reg_logistic(y2_tr, tX2_tr, max_iters, gamma)\n",
    "best_lambdas[3]= cross_validation_lambda_reg_logistic(y3_tr, tX3_tr, max_iters, gamma)\n",
    "\n",
    "print(best_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7104516857520505\n"
     ]
    }
   ],
   "source": [
    "w0, loss0 = reg_logistic_regression(y0_tr_new, tX0_tr_new,init_w0_new, best_lambdas[0], max_iters, gamma)\n",
    "w1, loss1 = reg_logistic_regression(y1_tr_new, tX1_tr_new,init_w1_new, best_lambdas[1], max_iters, gamma)\n",
    "w2, loss2 = reg_logistic_regression(y2_tr_new, tX2_tr_new,init_w2_new, best_lambdas[2], max_iters, gamma)\n",
    "w3, loss3 = reg_logistic_regression(y3_tr_new, tX3_tr_new,init_w3_new, best_lambdas[3], max_iters, gamma)\n",
    "\n",
    "y0_pred = predict_labels(w0, tX0_te)\n",
    "y1_pred = predict_labels(w1, tX1_te)\n",
    "y2_pred = predict_labels(w2, tX2_te)\n",
    "y3_pred = predict_labels(w3, tX3_te)\n",
    "\n",
    "grades = [0., 0., 0., 0.]\n",
    "res0 = np.where(y0_te[:,] == y0_pred[:,], 1, 0)\n",
    "grades[0] = np.mean(res0)\n",
    "res1 = np.where(y1_te[:,] == y1_pred[:,], 1, 0)\n",
    "grades[1] = np.mean(res0)\n",
    "res2 = np.where(y2_te[:,] == y2_pred[:,], 1, 0)\n",
    "grades[2] = np.mean(res2)\n",
    "res3 = np.where(y3_te[:,] == y3_pred[:,], 1, 0)\n",
    "grades[3] = np.mean(res3)\n",
    "grade = np.mean(grades)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, loss0 = reg_logistic_regression(y0_tr, tX0_tr,init_w0, best_lambdas[0], max_iters, gamma)\n",
    "w1, loss1 = reg_logistic_regression(y1_tr, tX1_tr,init_w1, best_lambdas[1], max_iters, gamma)\n",
    "w2, loss2 = reg_logistic_regression(y2_tr, tX2_tr,init_w2, best_lambdas[2], max_iters, gamma)\n",
    "w3, loss3 = reg_logistic_regression(y3_tr, tX3_tr,init_w3, best_lambdas[3], max_iters, gamma)\n",
    "\n",
    "\n",
    "y0_pred = predict_labels(w0, tX0_fin)\n",
    "y1_pred = predict_labels(w1, tX1_fin)\n",
    "y2_pred = predict_labels(w2, tX2_fin)\n",
    "y3_pred = predict_labels(w3, tX3_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate([y0_pred, y1_pred, y2_pred, y3_pred])\n",
    "ids_pred = np.concatenate([ids0_fin, ids1_fin, ids2_fin, ids3_fin])\n",
    "y_pred=rescale_y(y_pred, ids_fin, 0,-1)\n",
    "OUTPUT_PATH = 'results_reg_logistic_cross_noext_sep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation - Extended feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat:\n",
    "- Categorical accuracy:0.744\n",
    "- F1-Score: 0.463\n",
    "- Our grade: 0.760 - 0.731*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1]\n",
      "[4 1 4 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4 3 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "lambda_=6.72\n",
    "\n",
    "deg0=cross_validation_deg_reg_logistic(y0_tr, tX0_tr, max_iters, gamma,lambda_)\n",
    "deg1=cross_validation_deg_reg_logistic(y1_tr, tX1_tr, max_iters, gamma,lambda_)\n",
    "deg2=cross_validation_deg_reg_logistic(y2_tr, tX2_tr, max_iters, gamma,lambda_)\n",
    "deg3=cross_validation_deg_reg_logistic(y3_tr, tX3_tr, max_iters, gamma,lambda_)\n",
    "\n",
    "print(deg0)\n",
    "print(deg1)\n",
    "print(deg2)\n",
    "print(deg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX0_tr,tX0_tr_new,tX0_te,tX0_fin=build_poly_data(tX0_tr,tX0_tr_new,tX0_te,tX0_fin,deg0)\n",
    "tX1_tr,tX1_tr_new,tX1_te,tX1_fin=build_poly_data(tX1_tr,tX1_tr_new,tX1_te,tX1_fin,deg1)\n",
    "tX2_tr,tX2_tr_new,tX2_te,tX2_fin=build_poly_data(tX2_tr,tX2_tr_new,tX2_te,tX2_fin,deg2)\n",
    "tX3_tr,tX3_tr_new,tX3_te,tX3_fin=build_poly_data(tX3_tr,tX3_tr_new,tX3_te,tX3_fin,deg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 1e-05, 100.0, 18.32980710832434]\n"
     ]
    }
   ],
   "source": [
    "best_lambdas[0]= cross_validation_lambda_reg_logistic(y0_tr, tX0_tr, max_iters, gamma)\n",
    "best_lambdas[1]= cross_validation_lambda_reg_logistic(y1_tr, tX1_tr, max_iters, gamma)\n",
    "best_lambdas[2]= cross_validation_lambda_reg_logistic(y2_tr, tX2_tr, max_iters, gamma)\n",
    "best_lambdas[3]= cross_validation_lambda_reg_logistic(y3_tr, tX3_tr, max_iters, gamma)\n",
    "\n",
    "print(best_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7315074500544856\n"
     ]
    }
   ],
   "source": [
    "w0, loss0 = reg_logistic_regression(y0_tr_new, tX0_tr_new,init_w0_new, best_lambdas[0], max_iters, gamma)\n",
    "w1, loss1 = reg_logistic_regression(y1_tr_new, tX1_tr_new,init_w1_new, best_lambdas[1], max_iters, gamma)\n",
    "w2, loss2 = reg_logistic_regression(y2_tr_new, tX2_tr_new,init_w2_new, best_lambdas[2], max_iters, gamma)\n",
    "w3, loss3 = reg_logistic_regression(y3_tr_new, tX3_tr_new,init_w3_new, best_lambdas[3], max_iters, gamma)\n",
    "\n",
    "y0_pred = predict_labels(w0, tX0_te)\n",
    "y1_pred = predict_labels(w1, tX1_te)\n",
    "y2_pred = predict_labels(w2, tX2_te)\n",
    "y3_pred = predict_labels(w3, tX3_te)\n",
    "\n",
    "\n",
    "grades = [0., 0., 0., 0.]\n",
    "res0 = np.where(y0_te[:,] == y0_pred[:,], 1, 0)\n",
    "grades[0] = np.mean(res0)\n",
    "res1 = np.where(y1_te[:,] == y1_pred[:,], 1, 0)\n",
    "grades[1] = np.mean(res0)\n",
    "res2 = np.where(y2_te[:,] == y2_pred[:,], 1, 0)\n",
    "grades[2] = np.mean(res2)\n",
    "res3 = np.where(y3_te[:,] == y3_pred[:,], 1, 0)\n",
    "grades[3] = np.mean(res3)\n",
    "grade = np.mean(grades)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, loss0 = reg_logistic_regression(y0_tr, tX0_tr,init_w0, best_lambdas[0], max_iters, gamma)\n",
    "w1, loss1 = reg_logistic_regression(y1_tr, tX1_tr,init_w1, best_lambdas[1], max_iters, gamma)\n",
    "w2, loss2 = reg_logistic_regression(y2_tr, tX2_tr,init_w2, best_lambdas[2], max_iters, gamma)\n",
    "w3, loss3 = reg_logistic_regression(y3_tr, tX3_tr,init_w3, best_lambdas[3], max_iters, gamma)\n",
    "\n",
    "\n",
    "y0_pred = predict_labels(w0, tX0_fin)\n",
    "y1_pred = predict_labels(w1, tX1_fin)\n",
    "y2_pred = predict_labels(w2, tX2_fin)\n",
    "y3_pred = predict_labels(w3, tX3_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate([y0_pred, y1_pred, y2_pred, y3_pred])\n",
    "y_pred=rescale_y(y_pred, ids_fin, 0,-1)\n",
    "ids_pred = np.concatenate([ids0_fin, ids1_fin, ids2_fin, ids3_fin])\n",
    "OUTPUT_PATH = 'results_reg_logistic_cross_ext_sep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
