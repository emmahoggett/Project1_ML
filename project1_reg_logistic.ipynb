{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from data_analysis_logistic import *\n",
    "from implementation import *\n",
    "from cross_validation_reg_logistic import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"data/train.csv\" # download train data and supply path\n",
    "y_tr, tX_tr, ids_tr = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = \"data/test.csv\" #download train data and supply path\n",
    "y_fin, tX_fin, ids_fin = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_num = 0\n",
    "y0_tr, tX0_tr,y0_tr_new, tX0_tr_new, ids0_tr, y0_te, tX0_te, ids0_te, y0_fin, tX0_fin, ids0_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 1\n",
    "y1_tr, tX1_tr,y1_tr_new, tX1_tr_new, ids1_tr,y1_te, tX1_te, ids1_te, y1_fin, tX1_fin, ids1_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 2\n",
    "y2_tr, tX2_tr,y2_tr_new, tX2_tr_new, ids2_tr,y2_te, tX2_te, ids2_te, y2_fin, tX2_fin, ids2_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 3\n",
    "y3_tr, tX3_tr,y3_tr_new, tX3_tr_new, ids3_tr,y3_te, tX3_te, ids3_te, y3_fin, tX3_fin, ids3_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w0=np.zeros(tX0_tr.shape[1])\n",
    "init_w1=np.zeros(tX1_tr.shape[1])\n",
    "init_w2=np.zeros(tX2_tr.shape[1])\n",
    "init_w3=np.zeros(tX3_tr.shape[1])\n",
    "\n",
    "best_lambdas = [0., 0., 0., 0.,]\n",
    "\n",
    "max_iters=40\n",
    "gamma=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No cross validation - no extended feature - no separation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats:\n",
    "- Categorical accuracy: 0.663\n",
    "- F1-Score: 0.362\n",
    "- Our grade: 0.642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017433288221999882\n"
     ]
    }
   ],
   "source": [
    "ratio=0.8\n",
    "X_tr, X_te, Y_tr, Y_te, IDS_tr, IDS_te=split_data(tX_tr, y_tr, ids_tr, ratio, seed=1)\n",
    "X_tr, m, std = standardize(X_tr)\n",
    "X_te = standardize_te(X_te, m, std)\n",
    "\n",
    "init_w=np.zeros(X_tr.shape[1])\n",
    "best_lambda=test_lambda_cst(Y_tr,X_tr,Y_te,X_te,init_w, max_iters, gamma)\n",
    "\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64178\n"
     ]
    }
   ],
   "source": [
    "w, loss = reg_logistic_regression(Y_tr, X_tr,init_w, best_lambda, max_iters, gamma)\n",
    "\n",
    "y_pred = predict_labels(w, X_te)\n",
    "\n",
    "res = np.where(Y_te[:,] == y_pred[:,], 1, 0)\n",
    "grade = np.mean(res)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emma-hoggett/git_workspace/Project1_ML/implementation.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y*np.log(sigma)+(1-y)*np.log(1-sigma))+lambda_/2*np.dot(w.T,w)\n",
      "/home/emma-hoggett/git_workspace/Project1_ML/implementation.py:70: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y*np.log(sigma)+(1-y)*np.log(1-sigma))+lambda_/2*np.dot(w.T,w)\n",
      "/home/emma-hoggett/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:75: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "init_w=np.zeros(tX_tr.shape[1])\n",
    "w, loss = reg_logistic_regression(y_tr, tX_tr,init_w, best_lambda, max_iters, gamma)\n",
    "\n",
    "y_pred = predict_labels(w, tX_fin)\n",
    "ids_pred = ids_fin\n",
    "OUTPUT_PATH = 'results_reg_logistic_nocross_noext_nosep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation of lambda - No extended feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats:\n",
    "- Categorical accuracy: 0.678\n",
    "- F1-Score: 0.615\n",
    "- Our grade: 0.675 - *0.682\n",
    "\n",
    "\n",
    "A revoir: Les lambdas sont ils bien definies? Notamment pour lambda 0.\n",
    "\n",
    "*pas encore soumis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_k_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2a74c663a833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_lambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcross_validation_lambda_reg_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX0_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_lambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcross_validation_lambda_reg_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX1_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_lambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcross_validation_lambda_reg_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX2_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_lambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcross_validation_lambda_reg_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX3_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_workspace/Project1_ML/cross_validation_reg_logistic.py\u001b[0m in \u001b[0;36mcross_validation_lambda_reg_logistic\u001b[0;34m(y, tX, max_iters, gamma, k_fold)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlambdas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# split data in k fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mk_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_k_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# define lists to store the loss of training data and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mrmse_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_k_indices' is not defined"
     ]
    }
   ],
   "source": [
    "best_lambdas[0]= cross_validation_lambda_reg_logistic(y0_tr, tX0_tr, max_iters, gamma)\n",
    "best_lambdas[1]= cross_validation_lambda_reg_logistic(y1_tr, tX1_tr, max_iters, gamma)\n",
    "best_lambdas[2]= cross_validation_lambda_reg_logistic(y2_tr, tX2_tr, max_iters, gamma)\n",
    "best_lambdas[3]= cross_validation_lambda_reg_logistic(y3_tr, tX3_tr, max_iters, gamma)\n",
    "\n",
    "print(best_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6819202850397081\n"
     ]
    }
   ],
   "source": [
    "init_w0=np.zeros(tX0_tr_new.shape[1])\n",
    "init_w1=np.zeros(tX1_tr_new.shape[1])\n",
    "init_w2=np.zeros(tX2_tr_new.shape[1])\n",
    "init_w3=np.zeros(tX3_tr_new.shape[1])\n",
    "\n",
    "\n",
    "w0, loss0 = reg_logistic_regression(y0_tr_new, tX0_tr_new,init_w0, best_lambdas[0], max_iters, gamma)\n",
    "w1, loss1 = reg_logistic_regression(y1_tr_new, tX1_tr_new,init_w1, best_lambdas[1], max_iters, gamma)\n",
    "w2, loss2 = reg_logistic_regression(y2_tr_new, tX2_tr_new,init_w2, best_lambdas[2], max_iters, gamma)\n",
    "w3, loss3 = reg_logistic_regression(y3_tr_new, tX3_tr_new,init_w3, best_lambdas[3], max_iters, gamma)\n",
    "\n",
    "y0_pred = predict_labels(w0, tX0_te)\n",
    "y1_pred = predict_labels(w1, tX1_te)\n",
    "y2_pred = predict_labels(w2, tX2_te)\n",
    "y3_pred = predict_labels(w3, tX3_te)\n",
    "\n",
    "\n",
    "grades = [0., 0., 0., 0.]\n",
    "res0 = np.where(y0_te[:,] == y0_pred[:,], 1, 0)\n",
    "grades[0] = np.mean(res0)\n",
    "res1 = np.where(y1_te[:,] == y1_pred[:,], 1, 0)\n",
    "grades[1] = np.mean(res0)\n",
    "res2 = np.where(y2_te[:,] == y2_pred[:,], 1, 0)\n",
    "grades[2] = np.mean(res2)\n",
    "res3 = np.where(y3_te[:,] == y3_pred[:,], 1, 0)\n",
    "grades[3] = np.mean(res3)\n",
    "grade = np.mean(grades)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0_pred = predict_labels(w0, tX0_fin)\n",
    "y1_pred = predict_labels(w1, tX1_fin)\n",
    "y2_pred = predict_labels(w2, tX2_fin)\n",
    "y3_pred = predict_labels(w3, tX3_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate([y0_pred, y1_pred, y2_pred, y3_pred])\n",
    "ids_pred = np.concatenate([ids0_fin, ids1_fin, ids2_fin, ids3_fin])\n",
    "OUTPUT_PATH = 'results_reg_logistic_cross_noext_sep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation - Extended feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat:\n",
    "- Categorical accuracy:0.755\n",
    "- F1-Score: 0.534\n",
    "- Our grade: 0.771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_=0.022\n",
    "\n",
    "deg0=cross_validation_deg_reg_logistic(y0_tr, tX0_tr, max_iters, gamma,lambda_)\n",
    "deg1=cross_validation_deg_reg_logistic(y1_tr, tX1_tr, max_iters, gamma,lambda_)\n",
    "deg2=cross_validation_deg_reg_logistic(y2_tr, tX2_tr, max_iters, gamma,lambda_)\n",
    "deg3=cross_validation_deg_reg_logistic(y3_tr, tX3_tr, max_iters, gamma,lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX0_tr,tX0_te,tX0_fin=build_poly_data(tX0_tr,tX0_te,tX0_fin,deg0)\n",
    "tX1_tr,tX1_te,tX1_fin=build_poly_data(tX1_tr,tX1_te,tX1_fin,deg1)\n",
    "tX2_tr,tX2_te,tX2_fin=build_poly_data(tX2_tr,tX2_te,tX2_fin,deg2)\n",
    "tX3_tr,tX3_te,tX3_fin=build_poly_data(tX3_tr,tX3_te,tX3_fin,deg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188.73918221350996, 108.2636733874054, 188.73918221350996, 188.73918221350996]\n",
      "[1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[3 4 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "best_lambdas[0]= cross_validation_lambda_reg_logistic(y0_tr, tX0_tr, max_iters, gamma)\n",
    "best_lambdas[1]= cross_validation_lambda_reg_logistic(y1_tr, tX1_tr, max_iters, gamma)\n",
    "best_lambdas[2]= cross_validation_lambda_reg_logistic(y2_tr, tX2_tr, max_iters, gamma)\n",
    "best_lambdas[3]= cross_validation_lambda_reg_logistic(y3_tr, tX3_tr, max_iters, gamma)\n",
    "\n",
    "print(best_lambdas)\n",
    "print(deg0)\n",
    "print(deg1)\n",
    "print(deg2)\n",
    "print(deg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7682963323245651\n"
     ]
    }
   ],
   "source": [
    "init_w0=np.zeros(tX0_tr.shape[1])\n",
    "init_w1=np.zeros(tX1_tr.shape[1])\n",
    "init_w2=np.zeros(tX2_tr.shape[1])\n",
    "init_w3=np.zeros(tX3_tr.shape[1])\n",
    "\n",
    "w0, loss0 = reg_logistic_regression(y0_tr, tX0_tr,init_w0, best_lambdas[0], max_iters, gamma)\n",
    "w1, loss1 = reg_logistic_regression(y1_tr, tX1_tr,init_w1, best_lambdas[1], max_iters, gamma)\n",
    "w2, loss2 = reg_logistic_regression(y2_tr, tX2_tr,init_w2, best_lambdas[2], max_iters, gamma)\n",
    "w3, loss3 = reg_logistic_regression(y3_tr, tX3_tr,init_w3, best_lambdas[3], max_iters, gamma)\n",
    "\n",
    "y0_pred = predict_labels(w0, tX0_te)\n",
    "y1_pred = predict_labels(w1, tX1_te)\n",
    "y2_pred = predict_labels(w2, tX2_te)\n",
    "y3_pred = predict_labels(w3, tX3_te)\n",
    "\n",
    "\n",
    "grades = [0., 0., 0., 0.]\n",
    "res0 = np.where(y0_te[:,] == y0_pred[:,], 1, 0)\n",
    "grades[0] = np.mean(res0)\n",
    "res1 = np.where(y1_te[:,] == y1_pred[:,], 1, 0)\n",
    "grades[1] = np.mean(res0)\n",
    "res2 = np.where(y2_te[:,] == y2_pred[:,], 1, 0)\n",
    "grades[2] = np.mean(res2)\n",
    "res3 = np.where(y3_te[:,] == y3_pred[:,], 1, 0)\n",
    "grades[3] = np.mean(res3)\n",
    "grade = np.mean(grades)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0_pred = predict_labels(w0, tX0_fin)\n",
    "y1_pred = predict_labels(w1, tX1_fin)\n",
    "y2_pred = predict_labels(w2, tX2_fin)\n",
    "y3_pred = predict_labels(w3, tX3_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate([y0_pred, y1_pred, y2_pred, y3_pred])\n",
    "ids_pred = np.concatenate([ids0_fin, ids1_fin, ids2_fin, ids3_fin])\n",
    "OUTPUT_PATH = 'results_reg_logistic_cross_ext_sep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
