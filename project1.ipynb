{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x (250000, 30)\n",
      "shape of y (250000,)\n",
      "shape of ids (250000,)\n",
      "[46.226]\n",
      "[ 1.60937e+02  6.87680e+01  1.03235e+02  4.81460e+01  3.47300e+00\n",
      "  2.07800e+00  1.25157e+02  8.79000e-01  1.41400e+00  4.20140e+01\n",
      "  2.03900e+00 -3.01100e+00  3.69180e+01  5.01000e-01  1.03000e-01\n",
      "  4.47040e+01 -1.91600e+00  1.64546e+02  1.00000e+00  4.62260e+01]\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of x {}\".format(tX.shape))\n",
    "print(\"shape of y {}\".format(y.shape))\n",
    "print(\"shape of ids {}\".format(ids.shape))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the data\n",
    "N = tX.shape[0]\n",
    "tX0 = [] #data from collision creating 0 particules\n",
    "y0 = []\n",
    "ids0 = []\n",
    "tX1 = []\n",
    "y1 = []\n",
    "ids1 = []\n",
    "tX2 = []\n",
    "y2 = []\n",
    "ids2 = []\n",
    "tX3 = []\n",
    "y3 = []\n",
    "ids3 = []\n",
    "for i in range(N):\n",
    "    if (tX[i,22] == 0):\n",
    "        a = np.concatenate((tX[1,0:4], tX[1,7:12], tX[1,13:23], tX[1,29:30]))\n",
    "        tX0.append(a)\n",
    "        y0.append(y[i])\n",
    "        ids0.append(ids[i])\n",
    "    elif (tX[i,22] == 1):\n",
    "        a = np.concatenate((tX[1,0:4], tX[1,7:12], tX[1,13:26], tX[1,29:30]))\n",
    "        tX1.append(a)\n",
    "        y1.append(y[i])\n",
    "        ids1.append(ids[i])\n",
    "    elif (tX[i,22] == 2):\n",
    "        tX2.append(tX[i,:])\n",
    "        y2.append(y[i])\n",
    "        ids2.append(ids[i])\n",
    "    elif (tX[i,22] == 3):\n",
    "        tX3.append(tX[i,:])\n",
    "        y3.append(y[i])\n",
    "        ids3.append(ids[i])\n",
    "tX0 = np.asarray(tX0)\n",
    "y0 = np.asarray(y0)\n",
    "ids0 = np.asarray(ids0)\n",
    "tX1 = np.asarray(tX1)\n",
    "y1 = np.asarray(y1)\n",
    "ids1 = np.asarray(ids1)\n",
    "tX2 = np.asarray(tX2)\n",
    "y2 = np.asarray(y2)\n",
    "ids2 = np.asarray(ids2)\n",
    "tX3 = np.asarray(tX3)\n",
    "y3 = np.asarray(y3)\n",
    "ids3 = np.asarray(ids3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x0 (99913, 20)\n",
      "shape of y0 (99913,)\n",
      "shape of ids0 (99913,)\n",
      "shape of x1 (77544, 23)\n",
      "shape of y1 (77544,)\n",
      "shape of ids1 (77544,)\n",
      "shape of x2 (50379, 30)\n",
      "shape of y2 (50379,)\n",
      "shape of ids2 (50379,)\n",
      "shape of x3 (22164, 30)\n",
      "shape of y3 (22164,)\n",
      "shape of ids3 (22164,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of x0 {}\".format(tX0.shape))\n",
    "print(\"shape of y0 {}\".format(y0.shape))\n",
    "print(\"shape of ids0 {}\".format(ids0.shape))\n",
    "print(\"shape of x1 {}\".format(tX1.shape))\n",
    "print(\"shape of y1 {}\".format(y1.shape))\n",
    "print(\"shape of ids1 {}\".format(ids1.shape))\n",
    "print(\"shape of x2 {}\".format(tX2.shape))\n",
    "print(\"shape of y2 {}\".format(y2.shape))\n",
    "print(\"shape of ids2 {}\".format(ids2.shape))\n",
    "print(\"shape of x3 {}\".format(tX3.shape))\n",
    "print(\"shape of y3 {}\".format(y3.shape))\n",
    "print(\"shape of ids3 {}\".format(ids3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.87059290e+00  1.36172983e+01  6.00248012e+00  8.21213729e-01\n",
      " -3.04829910e+01  1.12655225e+02 -1.66524928e+00 -1.33934335e+03\n",
      " -4.79282806e+01  1.80910475e+01 -1.14721546e+02 -2.27103624e+02\n",
      "  6.71261007e+00 -7.12719378e+02  7.58844368e+03 -1.11110378e+01\n",
      "  2.52968288e+02  5.75893326e-02 -1.38894860e+02 -1.25559519e+01]\n",
      "[ 8.03494349e-05 -7.20202266e-03 -6.05417274e-03 -5.47559077e-04\n",
      " -1.93874702e-02  4.73451615e-04 -2.60379061e-02  3.25106299e-01\n",
      " -3.80780008e-05 -2.72785897e+00 -2.21220141e-01  9.50794097e-02\n",
      "  6.40351626e-02  2.73611865e+00 -3.31801110e-04 -9.54325152e-04\n",
      "  2.74087539e+00 -5.34165279e-04  9.73498884e-04  3.69225050e-03\n",
      "  3.54487165e-04 -5.43344617e-04 -3.30448034e-01 -1.40800496e-03\n",
      "  8.31432874e-04  1.02117271e-03 -1.68047418e-03 -5.83664770e-03\n",
      " -1.11088005e-02  2.72831890e+00]\n"
     ]
    }
   ],
   "source": [
    "from implementation import least_squares\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "D = tX.shape[1]\n",
    "\n",
    "# Start gradient descent.\n",
    "#start_time = datetime.datetime.now()\n",
    "w, loss = least_squares(y, tX)\n",
    "w0, loss0 = least_squares(y0, tX0)\n",
    "w1, loss1 = least_squares(y1, tX1)\n",
    "w2, loss2 = least_squares(y2, tX2)\n",
    "w3, loss3 = least_squares(y3, tX3)\n",
    "#end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "#exection_time = (end_time - start_time).total_seconds()\n",
    "#print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(w0)\n",
    "print(w)\n",
    "#print(\"loss={l}, w0={w0}, w1={w1}\".format(l=loss, w0=w[0], w1=w[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"test.csv\" # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'results.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
