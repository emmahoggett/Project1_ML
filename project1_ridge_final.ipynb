{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"data/train.csv\" # download train data and supply path\n",
    "y_tr, tX_tr, ids_tr = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"data/test.csv\" #download test data and supply path\n",
    "y_fin, tX_fin, ids_fin = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train (80%) and test (20%) parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8;\n",
    "tX_tr, tX_te, y_tr, y_te, ids_tr, ids_te = split_data(tX_tr, y_tr, ids_tr, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following operations:\n",
    "1. Split every dataset into 4 different groups depending on the value of the `PRI_jet_num` parameter in column 22. Some columns will be completely undetermined for some of the groups after this split: delete the undetermined columns (example: if `PRI_jet_num=0`, `DER_deltaeta_jet_jet` (column 4) will always be undetermined)\n",
    "2. Replace undefined `DER_mass_MMC` values in column 0 by the mean of the defined values in that same column.\n",
    "3. Standardize every column (subtract the mean and divide by the standard deviation).\n",
    "4. Delete the training points containing outlier values for some of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_num = 0\n",
    "y0_tr, tX0_tr, ids0_tr, y0_te, tX0_te, ids0_te, y0_fin, tX0_fin, ids0_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_fin, tX_fin, ids_fin)\n",
    "\n",
    "jet_num = 1\n",
    "y1_tr, tX1_tr, ids1_tr, y1_te, tX1_te, ids1_te, y1_fin, tX1_fin, ids1_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_fin, tX_fin, ids_fin)\n",
    "\n",
    "jet_num = 2\n",
    "y2_tr, tX2_tr, ids2_tr, y2_te, tX2_te, ids2_te, y2_fin, tX2_fin, ids2_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_fin, tX_fin, ids_fin)\n",
    "\n",
    "jet_num = 3\n",
    "y3_tr, tX3_tr, ids3_tr, y3_te, tX3_te, ids3_te, y3_fin, tX3_fin, ids3_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_fin, tX_fin, ids_fin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial feature expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementation import *\n",
    "from optimization import * \n",
    "from proj1_helpers import *\n",
    "from data_analysis_logistic import *\n",
    "from cross_validation_logistic import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every feature, determine the optimal degree for the polynomial feature expansion by cross-validation on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg0 = np.ones(tX0_tr.shape[1],np.int64)\n",
    "deg1 = np.ones(tX1_tr.shape[1],np.int64)\n",
    "deg2 = np.ones(tX2_tr.shape[1],np.int64)\n",
    "deg3 = np.ones(tX3_tr.shape[1],np.int64)\n",
    "\n",
    "for feat_ind in np.arange(len(deg0)):\n",
    "    deg0[feat_ind] =  cross_validation_degree(y0_tr, tX0_tr, feat_ind, deg0)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg1)):\n",
    "    deg1[feat_ind] =  cross_validation_degree(y1_tr, tX1_tr, feat_ind, deg1)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg2)):\n",
    "    deg2[feat_ind] =  cross_validation_degree(y2_tr, tX2_tr, feat_ind, deg2)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg3)):\n",
    "    deg3[feat_ind] =  cross_validation_degree(y3_tr, tX3_tr, feat_ind, deg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand all the feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX0_tr,tX0_te,tX0_fin = build_poly_data(tX0_tr,tX0_te,tX0_fin,deg0)\n",
    "tX1_tr,tX1_te,tX1_fin = build_poly_data(tX1_tr,tX1_te,tX1_fin,deg1)\n",
    "tX2_tr,tX2_te,tX2_fin = build_poly_data(tX2_tr,tX2_te,tX2_fin,deg2)\n",
    "tX3_tr,tX3_te,tX3_fin = build_poly_data(tX3_tr,tX3_te,tX3_fin,deg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, loss0 = ridge_regression(y0_tr, tX0_tr, lambda_)\n",
    "w1, loss1 = ridge_regression(y1_tr, tX1_tr, lambda_)\n",
    "w2, loss2 = ridge_regression(y2_tr, tX2_tr, lambda_)\n",
    "w3, loss3 = ridge_regression(y3_tr, tX3_tr, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the labels with the 4 different models for every different value of `PRI_jet_num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0_pred = predict_labels(w0, tX0_fin)\n",
    "y1_pred = predict_labels(w1, tX1_fin)\n",
    "y2_pred = predict_labels(w2, tX2_fin)\n",
    "y3_pred = predict_labels(w3, tX3_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate([y0_pred, y1_pred, y2_pred, y3_pred])\n",
    "ids_pred = np.concatenate([ids0_fin, ids1_fin, ids2_fin, ids3_fin])\n",
    "\n",
    "OUTPUT_PATH = 'data/results_ridge.csv' #name of output file for submission\n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238,)\n"
     ]
    }
   ],
   "source": [
    "print(ids_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Our score : 0.822\n",
    "# - Categorical accuracy : 0.802\n",
    "# - F1 score : 0.638"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
