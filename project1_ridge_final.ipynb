{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"data/train.csv\" # download train data and supply path\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"data/test.csv\" #download data to predict and supply path\n",
    "y_pred, tX_pred, ids_pred = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test, so we can test ourselves the accuracy of our model. We usually set `ratio` to 0.8.\n",
    "\n",
    "If we want to make an actual submission file, we will train on all our data and therefore `ratio` will be set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1\n",
    "tX_tr, tX_te, y_tr, y_te, ids_tr, ids_te = split_data(tX, y, ids, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following operations:\n",
    "1. Split every dataset into 8 different groups depending on the value of the `PRI_jet_num` parameter in column 22 and on whether the `DER_mass_MMC` parameter is defined in column 0.\n",
    "2. Get rid of undetermined columns (-999). *Example: if `PRI_jet_num=0`, `DER_deltaeta_jet_jet` (column 4) will always be undetermined*\n",
    "3. Standardize every column (subtract the mean and divide by the standard deviation).\n",
    "4. Delete the training points containing outlier values for some of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_num = 0\n",
    "# d: defined DER_mass_MMC, u: undefined mass\n",
    "y0d_tr, tX0d_tr, ids0d_tr, y0d_te, tX0d_te, ids0d_te, y0d_pred, tX0d_pred, ids0d_pred = data_processing(jet_num, 'defined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)\n",
    "y0u_tr, tX0u_tr, ids0u_tr, y0u_te, tX0u_te, ids0u_te, y0u_pred, tX0u_pred, ids0u_pred = data_processing(jet_num, 'undefined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)\n",
    "\n",
    "jet_num = 1\n",
    "y1d_tr, tX1d_tr, ids1d_tr, y1d_te, tX1d_te, ids1d_te, y1d_pred, tX1d_pred, ids1d_pred = data_processing(jet_num, 'defined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)\n",
    "y1u_tr, tX1u_tr, ids1u_tr, y1u_te, tX1u_te, ids1u_te, y1u_pred, tX1u_pred, ids1u_pred = data_processing(jet_num, 'undefined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)\n",
    "\n",
    "jet_num = 2\n",
    "y2d_tr, tX2d_tr, ids2d_tr, y2d_te, tX2d_te, ids2d_te, y2d_pred, tX2d_pred, ids2d_pred = data_processing(jet_num, 'defined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)\n",
    "y2u_tr, tX2u_tr, ids2u_tr, y2u_te, tX2u_te, ids2u_te, y2u_pred, tX2u_pred, ids2u_pred = data_processing(jet_num, 'undefined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)\n",
    "\n",
    "jet_num = 3\n",
    "y3d_tr, tX3d_tr, ids3d_tr, y3d_te, tX3d_te, ids3d_te, y3d_pred, tX3d_pred, ids3d_pred = data_processing(jet_num, 'defined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)\n",
    "y3u_tr, tX3u_tr, ids3u_tr, y3u_te, tX3u_te, ids3u_te, y3u_pred, tX3u_pred, ids3u_pred = data_processing(jet_num, 'undefined', y_tr, tX_tr, ids_tr, y_te, tX_te, ids_te, y_pred, tX_pred, ids_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial feature expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementation import *\n",
    "from optimization import * \n",
    "from proj1_helpers import *\n",
    "from data_analysis_logistic import * ### Why?\n",
    "from cross_validation_logistic import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every feature, determine the optimal degree for the polynomial feature expansion by 4-fold cross-validation on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg0d = np.ones(tX0d_tr.shape[1],np.int64)\n",
    "deg1d = np.ones(tX1d_tr.shape[1],np.int64)\n",
    "deg2d = np.ones(tX2d_tr.shape[1],np.int64)\n",
    "deg3d = np.ones(tX3d_tr.shape[1],np.int64)\n",
    "\n",
    "deg0u = np.ones(tX0u_tr.shape[1],np.int64)\n",
    "deg1u = np.ones(tX1u_tr.shape[1],np.int64)\n",
    "deg2u = np.ones(tX2u_tr.shape[1],np.int64)\n",
    "deg3u = np.ones(tX3u_tr.shape[1],np.int64)\n",
    "\n",
    "for feat_ind in np.arange(len(deg0d)):\n",
    "    deg0d[feat_ind] =  cross_validation_degree(y0d_tr, tX0d_tr, feat_ind, deg0d)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg1d)):\n",
    "    deg1d[feat_ind] =  cross_validation_degree(y1d_tr, tX1d_tr, feat_ind, deg1d)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg2d)):\n",
    "    deg2d[feat_ind] =  cross_validation_degree(y2d_tr, tX2d_tr, feat_ind, deg2d)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg3d)):\n",
    "    deg3d[feat_ind] =  cross_validation_degree(y3d_tr, tX3d_tr, feat_ind, deg3d)\n",
    "\n",
    "for feat_ind in np.arange(len(deg0u)):\n",
    "    deg0u[feat_ind] =  cross_validation_degree(y0u_tr, tX0u_tr, feat_ind, deg0u)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg1u)):\n",
    "    deg1u[feat_ind] =  cross_validation_degree(y1u_tr, tX1u_tr, feat_ind, deg1u)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg2u)):\n",
    "    deg2u[feat_ind] =  cross_validation_degree(y2u_tr, tX2u_tr, feat_ind, deg2u)\n",
    "    \n",
    "for feat_ind in np.arange(len(deg3u)):\n",
    "    deg3u[feat_ind] =  cross_validation_degree(y3u_tr, tX3u_tr, feat_ind, deg3u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand all the feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX0d_tr = expand(tX0d_tr, deg0d)\n",
    "tX0d_te = expand(tX0d_te, deg0d)\n",
    "tX0d_pred = expand(tX0d_pred, deg0d)\n",
    "\n",
    "tX1d_tr = expand(tX1d_tr, deg1d)\n",
    "tX1d_te = expand(tX1d_te, deg1d)\n",
    "tX1d_pred = expand(tX1d_pred, deg1d)\n",
    "\n",
    "tX2d_tr = expand(tX2d_tr, deg2d)\n",
    "tX2d_te = expand(tX2d_te, deg2d)\n",
    "tX2d_pred = expand(tX2d_pred, deg2d)\n",
    "\n",
    "tX3d_tr = expand(tX3d_tr, deg3d)\n",
    "tX3d_te = expand(tX3d_te, deg3d)\n",
    "tX3d_pred = expand(tX3d_pred, deg3d)\n",
    "\n",
    "tX0u_tr = expand(tX0u_tr, deg0u)\n",
    "tX0u_te = expand(tX0u_te, deg0u)\n",
    "tX0u_pred = expand(tX0u_pred, deg0u)\n",
    "\n",
    "tX1u_tr = expand(tX1u_tr, deg1u)\n",
    "tX1u_te = expand(tX1u_te, deg1u)\n",
    "tX1u_pred = expand(tX1u_pred, deg1u)\n",
    "\n",
    "tX2u_tr = expand(tX2u_tr, deg2u)\n",
    "tX2u_te = expand(tX2u_te, deg2u)\n",
    "tX2u_pred = expand(tX2u_pred, deg2u)\n",
    "\n",
    "tX3u_tr = expand(tX3u_tr, deg3u)\n",
    "tX3u_te = expand(tX3u_te, deg3u)\n",
    "tX3u_pred = expand(tX3u_pred, deg3u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0d, loss0d = ridge_regression(y0d_tr, tX0d_tr, lambda_)\n",
    "w1d, loss1d = ridge_regression(y1d_tr, tX1d_tr, lambda_)\n",
    "w2d, loss2d = ridge_regression(y2d_tr, tX2d_tr, lambda_)\n",
    "w3d, loss3d = ridge_regression(y3d_tr, tX3d_tr, lambda_)\n",
    "\n",
    "w0u, loss0u = ridge_regression(y0u_tr, tX0u_tr, lambda_)\n",
    "w1u, loss1u = ridge_regression(y1u_tr, tX1u_tr, lambda_)\n",
    "w2u, loss2u = ridge_regression(y2u_tr, tX2u_tr, lambda_)\n",
    "w3u, loss3u = ridge_regression(y3u_tr, tX3u_tr, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score of the model\n",
    "*In this part we grade our model by using it on the test dataset that we kept when we did the split at the begining. Therefore, this part will only be useful if `ratio` is not set to 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the labels with the 4 different models for every different value of `PRI_jet_num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0d_pred = predict_labels(w0d, tX0d_te)\n",
    "y1d_pred = predict_labels(w1d, tX1d_te)\n",
    "y2d_pred = predict_labels(w2d, tX2d_te)\n",
    "y3d_pred = predict_labels(w3d, tX3d_te)\n",
    "\n",
    "y0u_pred = predict_labels(w0u, tX0u_te)\n",
    "y1u_pred = predict_labels(w1u, tX1u_te)\n",
    "y2u_pred = predict_labels(w2u, tX2u_te)\n",
    "y3u_pred = predict_labels(w3u, tX3u_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of right predictions in every set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_0d = np.sum(np.where(y0d_te == y0d_pred, 1, 0))\n",
    "n_1d = np.sum(np.where(y1d_te == y1d_pred, 1, 0))\n",
    "n_2d = np.sum(np.where(y2d_te == y2d_pred, 1, 0))\n",
    "n_3d = np.sum(np.where(y3d_te == y3d_pred, 1, 0))\n",
    "\n",
    "n_0u = np.sum(np.where(y0u_te == y0u_pred, 1, 0))\n",
    "n_1u = np.sum(np.where(y1u_te == y1u_pred, 1, 0))\n",
    "n_2u = np.sum(np.where(y2u_te == y2u_pred, 1, 0))\n",
    "n_3u = np.sum(np.where(y3u_te == y3u_pred, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.8092.\n"
     ]
    }
   ],
   "source": [
    "score = (n_0d + n_1d + n_2d + n_3d + n_0u + n_1u + n_2u + n_3u)/y_te.shape[0]\n",
    "\n",
    "print(f\"The score is {score}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the labels with the 8 different models for every different value of `PRI_jet_num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0d_pred = predict_labels(w0d, tX0d_pred)\n",
    "y1d_pred = predict_labels(w1d, tX1d_pred)\n",
    "y2d_pred = predict_labels(w2d, tX2d_pred)\n",
    "y3d_pred = predict_labels(w3d, tX3d_pred)\n",
    "\n",
    "y0u_pred = predict_labels(w0u, tX0u_pred)\n",
    "y1u_pred = predict_labels(w1u, tX1u_pred)\n",
    "y2u_pred = predict_labels(w2u, tX2u_pred)\n",
    "y3u_pred = predict_labels(w3u, tX3u_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate([y0d_pred, y1d_pred, y2d_pred, y3d_pred, y0u_pred, y1u_pred, y2u_pred, y3u_pred])\n",
    "ids_pred = np.concatenate([ids0d_pred, ids1d_pred, ids2d_pred, ids3d_pred, ids0u_pred, ids1u_pred, ids2u_pred, ids3u_pred])\n",
    "\n",
    "OUTPUT_PATH = 'data/results_ridge.csv' #name of output file for submission\n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238,)\n"
     ]
    }
   ],
   "source": [
    "print(ids_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Our score : 0.822\n",
    "# - Categorical accuracy : 0.802\n",
    "# - F1 score : 0.638"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
