{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from data_analysis_logistic import *\n",
    "from optimization import*\n",
    "from implementation import *\n",
    "from cross_validation_logistic import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"data/train.csv\" # download train data and supply path\n",
    "y_tr, tX_tr, ids_tr = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = \"data/test.csv\" #download train data and supply path\n",
    "y_fin, tX_fin, ids_fin = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "## Separation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jet_num = 0\n",
    "y0_tr, tX0_tr,y0_tr_new, tX0_tr_new, ids0_tr, y0_te, tX0_te, ids0_te, y0_fin, tX0_fin, ids0_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 1\n",
    "y1_tr, tX1_tr,y1_tr_new, tX1_tr_new, ids1_tr,y1_te, tX1_te, ids1_te, y1_fin, tX1_fin, ids1_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 2\n",
    "y2_tr, tX2_tr,y2_tr_new, tX2_tr_new, ids2_tr,y2_te, tX2_te, ids2_te, y2_fin, tX2_fin, ids2_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n",
    "jet_num = 3\n",
    "y3_tr, tX3_tr,y3_tr_new, tX3_tr_new, ids3_tr,y3_te, tX3_te, ids3_te, y3_fin, tX3_fin, ids3_fin = data_analysis(jet_num, y_tr, tX_tr, ids_tr, y_fin, tX_fin, ids_fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w0=np.zeros(tX0_tr.shape[1])\n",
    "init_w1=np.zeros(tX1_tr.shape[1])\n",
    "init_w2=np.zeros(tX2_tr.shape[1])\n",
    "init_w3=np.zeros(tX3_tr.shape[1])\n",
    "\n",
    "max_iters=40\n",
    "gamma=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No extended feature - no separation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats:\n",
    "- Categorical accuracy: \n",
    "- F1-Score: \n",
    "- Our grade: 0.642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=0.8\n",
    "X_tr, X_te, Y_tr, Y_te, IDS_tr, IDS_te=split_data(tX_tr, y_tr, ids_tr, ratio, seed=1)\n",
    "X_tr, m, std = standardize(X_tr)\n",
    "X_te = standardize_te(X_te, m, std)\n",
    "\n",
    "init_w=np.zeros(X_tr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64176\n"
     ]
    }
   ],
   "source": [
    "w, loss = logistic_regression(Y_tr, X_tr,init_w, max_iters, gamma)\n",
    "\n",
    "y_pred = predict_labels(w, X_te)\n",
    "\n",
    "res = np.where(Y_te[:,] == y_pred[:,], 1, 0)\n",
    "grade = np.mean(res)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w=np.zeros(tX_tr.shape[1])\n",
    "tX_tr, m, std = standardize(tX_tr)\n",
    "w, loss = logistic_regression(y_tr, tX_tr,init_w, max_iters, gamma)\n",
    "\n",
    "y_pred = predict_labels(w, tX_fin)\n",
    "ids_pred = ids_fin\n",
    "OUTPUT_PATH = 'results_logistic_noext_nosep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Extended feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat:\n",
    "- Categorical accuracy: 0.755\n",
    "- F1-Score: 0.534\n",
    "- Our grade: 0.771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg0=cross_validation_deg_logistic(y0_tr, tX0_tr, max_iters, gamma)\n",
    "deg1=cross_validation_deg_logistic(y1_tr, tX1_tr, max_iters, gamma)\n",
    "deg2=cross_validation_deg_logistic(y2_tr, tX2_tr, max_iters, gamma)\n",
    "deg3=cross_validation_deg_logistic(y3_tr, tX3_tr, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX0_tr,tX0_te,tX0_fin=build_poly_data(tX0_tr,tX0_te,tX0_fin,deg0)\n",
    "tX1_tr,tX1_te,tX1_fin=build_poly_data(tX1_tr,tX1_te,tX1_fin,deg1)\n",
    "tX2_tr,tX2_te,tX2_fin=build_poly_data(tX2_tr,tX2_te,tX2_fin,deg2)\n",
    "tX3_tr,tX3_te,tX3_fin=build_poly_data(tX3_tr,tX3_te,tX3_fin,deg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.770783086338484\n"
     ]
    }
   ],
   "source": [
    "init_w0=np.zeros(tX0_tr.shape[1])\n",
    "init_w1=np.zeros(tX1_tr.shape[1])\n",
    "init_w2=np.zeros(tX2_tr.shape[1])\n",
    "init_w3=np.zeros(tX3_tr.shape[1])\n",
    "\n",
    "w0, loss0 = logistic_regression(y0_tr, tX0_tr,init_w0, max_iters, gamma)\n",
    "w1, loss1 = logistic_regression(y1_tr, tX1_tr,init_w1, max_iters, gamma)\n",
    "w2, loss2 = logistic_regression(y2_tr, tX2_tr,init_w2, max_iters, gamma)\n",
    "w3, loss3 = logistic_regression(y3_tr, tX3_tr,init_w3, max_iters, gamma)\n",
    "\n",
    "y0_pred = predict_labels(w0, tX0_te)\n",
    "y1_pred = predict_labels(w1, tX1_te)\n",
    "y2_pred = predict_labels(w2, tX2_te)\n",
    "y3_pred = predict_labels(w3, tX3_te)\n",
    "\n",
    "\n",
    "grades = [0., 0., 0., 0.]\n",
    "res0 = np.where(y0_te[:,] == y0_pred[:,], 1, 0)\n",
    "grades[0] = np.mean(res0)\n",
    "res1 = np.where(y1_te[:,] == y1_pred[:,], 1, 0)\n",
    "grades[1] = np.mean(res0)\n",
    "res2 = np.where(y2_te[:,] == y2_pred[:,], 1, 0)\n",
    "grades[2] = np.mean(res2)\n",
    "res3 = np.where(y3_te[:,] == y3_pred[:,], 1, 0)\n",
    "grades[3] = np.mean(res3)\n",
    "grade = np.mean(grades)\n",
    "\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0_pred = predict_labels(w0, tX0_fin)\n",
    "y1_pred = predict_labels(w1, tX1_fin)\n",
    "y2_pred = predict_labels(w2, tX2_fin)\n",
    "y3_pred = predict_labels(w3, tX3_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate([y0_pred, y1_pred, y2_pred, y3_pred])\n",
    "ids_pred = np.concatenate([ids0_fin, ids1_fin, ids2_fin, ids3_fin])\n",
    "OUTPUT_PATH = 'results_logistic_ext_sep.csv' \n",
    "create_csv_submission(ids_pred, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
